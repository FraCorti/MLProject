\section{Introduction}
Our goal was to create a Neural Network model simulator and apply it to MONK's classification problems and the ML CUP regression problem. 
We developed a library with the aim of building, training and testing feedforward neural networks using back-propagation and multiple versions of gradient descent. Namely stochastic, mini-batch and batch with Nesterov Momentum and weight decay as regularization and using different activation functions and loss functions. 
Our assumption was to find the best model for each problem. This was reached by looking for a smooth and compact loss function. We achieved this by using grid search technique with k-fold cross validation. We paid attention not to commit overfitting using regularization technique such as weight decay. 